

% sldies for T-61.6080 special course in bioinformatics 2, Spring 2015
\documentclass[first=purple,second=dgreen,logo=redexc]{aaltoslides}

% macro
\input{slide_macro_su.tex}

% title and other informtions
\title{Multilabel classification through structured output learning}
\subtitle{Multilabel classification}
\author[H. Su]{Hongyu Su}
\institute[SCI]{Department of Computer Science\\School of Science, Aalto University\\hongyu.su@aalto.fi}
\aaltofootertext{Molecular classification}{Hongyu Su}{\today}%{\arabic{page}/\pageref{LastPage}\ }

%\date{Version 1.0, \today}
\date{ \today}
\AtBeginSection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,subsection]
  \end{frame}
}


% start the main contain of the document
\begin{document}


\aaltotitleframe



\footnotesize{

\iffalse
\begin{frame}{Content}
	\begin{itemize}
		\item Single label classification
		\item Multilabel classification
		\item Structured output learning
		\item 
	\end{itemize}
\end{frame}
\fi


\begin{frame}{Machine learning}
	\begin{itemize}
		\item In 1946, the first fully electronic computer was built, known as ENIAC.
		\begin{center}
			\includegraphics[scale=0.2]{./figures/eniac4.jpg}
			\text{    }
			\includegraphics[scale=0.2]{./figures/eniac.jpg}
		\end{center}
		\item In 1957, the perceptron algorithm was invented \citep{Rosenblatt58}.
		\item In 1958, New York Time wrote perceptron as ``the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence''.
		\item In 1959, Arthur Samuel defined machine learning as a ``Field of study that gives computers the ability to learn without being explicitly programmed''.
	\end{itemize}
\end{frame}

\begin{frame}{Main scope of this dissertation}
	\begin{itemize}
		\item The dissertation focuses on classification learning, and multilabel classification in particular. 
	\end{itemize}
\end{frame}
	
\begin{frame}{Example: dog vs. cat?}
	\begin{itemize}
		\item We have $5000$ pictures of dog and $5000$ pictures of cat.
		\begin{center}
			\includegraphics[scale=0.3]{./figures/dog.jpg}
			\text{     }
			\includegraphics[scale=0.3]{./figures/cat.jpg}
		\end{center}
		\item Computer digitalize each picture into $100\times100$ pixels.
		\item Given a new picture, we want to answer: is it a dog or a cat?
		\item Simple task for human, dog, or cat.
		\item \citet{Golle08machine} claimed this is a difficult task for machines with only $82.7\%$ \textit{accuracy} (probability of getting a right answer).
		\item In 2013, $98.5\%$ accuracy was reported in a Kaggle competition (https://www.kaggle.com/c/dogs-vs-cats).
		\item Why is this useful?
	\end{itemize}
\end{frame}

\begin{frame}{In human verification system}
	\begin{itemize}
		\item Human verification system is a program that protects website from robots by generating and grading test that human can pass but machine cannot.
		\item CAPTCHA system \citep{Ahn03captcha} uses distorted text.
		\begin{center}
			\includegraphics[scale=0.2]{./figures/captcha.png}
		\end{center}
		\item ASIRRA system \citep{Elson07asirra} uses images.
		\begin{center}
			\includegraphics[scale=0.2]{./figures/assira.jpg}
		\end{center}
		\item To test if the ASIRRA system is safe from machine learning attack.
		\begin{itemize}
			\footnotesize
			\item One should get all $12$ pictures right!
			\item Accuracy for machine is $(98.5\%)^{12} \approx 83.4\%$.
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{In search engine}
	\begin{itemize}
		\item If machine can assign cat/dog to all pictures correctly, we can search pictures with keywords.
		\only<1>{\item Search all \textbf{cat} pictures.}
		\only<2>{\item Search all \textbf{dog} pictures.}
	\end{itemize}
	\only<1>{
	\begin{center}
		\includegraphics[scale=0.13]{./figures/googlecat.png}
	\end{center}
	}
	\only<2>{
	\begin{center}
		\includegraphics[scale=0.13]{./figures/googledog.png}
	\end{center}
	}
\end{frame}


\begin{frame}{Single label classification}
	\begin{itemize}
		\item In machine learning, the problem is known as \textit{single label classification}.
		\begin{itemize}
			\footnotesize
			\item Input is an object $\vx$ (e.g., a picture).
			\item Output is an attribute $y$ called \textit{label}\\ (e.g., $y=+1$:dog, $y=-1$:cat).
			\item Explore a set of known object and label pairs called \textit{training data}
			\begin{align*}
				\{\underbrace{(\vx_1,+1),\cdots,(\vx_{5000},+1)}_{\text{dog pictures}},\underbrace{(\vx_{5001},-1),\cdots, (\vx_{10000},-1)}_{\text{cat pictures}}\}.
			\end{align*}
			\item Learn a \textit{mapping function} $f$ that predicts the label of a new object.
			\begin{align*}
				\vx\overset{f}{\rightarrow}y,y\in\{+1,-1\}.
			\end{align*}
		\end{itemize}
		\item Many algorithms are available to tackle single label classification problems, e.g., support vector machines \citep{Cortes95support}, logistic regression \citep{Chen99}.
	\end{itemize}
\end{frame}


\begin{frame}{Support vector machine}
	\only<1>{
	\begin{itemize}
		\item Represent objects into a feature space (e.g., points in 2D space.)
		\item A feature space is a high dimensional space made by \textit{kernel functions} \citep{Taylor04kernel}.
	\end{itemize}}
	\only<2>{
	\begin{itemize}
		\item Find a \textit{hyperplane} (\textit{classifier}) to separate objects of two classes.
		\item Minimize the number of mistakes made by the classifier. This is known as \textit{empirical risk minimization} \citep{Vapnik92principles}.
	\end{itemize}}
	\only<3>{
	\begin{itemize}
		\item We want the hyperplane to separate two classes with a big ``gap''.
		\item ``Gap'' is known as \textit{margin} which gives us enough confident to deal with new objects \citep{Evgeniou99a,Evgeniou02regularization}.
	\end{itemize}}
	\only<4>{
	\begin{itemize}
		\item Represent the new object into the same feature space.
		\item The classifier will generate the label of the new object according to its side.
	\end{itemize}}
	\begin{center}
		\only<1>{\includegraphics[scale=0.25]{./figures/svm0.pdf}}
		\only<2>{\includegraphics[scale=0.25]{./figures/svm2.pdf}}
		\only<3>{\includegraphics[scale=0.25]{./figures/svm.pdf}}
		\only<4>{\includegraphics[scale=0.25]{./figures/svm1.pdf}}
\end{center}
\end{frame}

\begin{frame}{Image annotation task}
	\begin{itemize}
		\item We are often interested in multiple attributes of a single picture.
		\item For example, we want to assign multiple tags to one picture.
		\begin{center}
			\{boat, sea, sun, beach, people, dog, cat\}
		\end{center}
		\item Correct annotations will allow us to search with multiple attributes.
		\only<1>{\item Search with \textbf{dog \& cat}.}
		\only<2>{\item Search with \textbf{sun \& beach \& people}.}
		\only<3>{\item Search with \textbf{boat \& sea \& sun}.}
	\end{itemize}
	\only<1>{
	\begin{center}
		\includegraphics[scale=0.11]{./figures/googledogcat.png}
	\end{center}
	}
	\only<2>{
	\begin{center}
		\includegraphics[scale=0.11]{./figures/googlesun.png}
	\end{center}
	}
	\only<3>{
	\begin{center}
		\includegraphics[scale=0.11]{./figures/googleboat.png}
	\end{center}
	}
\end{frame}


\begin{frame}{Multilabel classification}
	\begin{itemize}
		\item The problem is known as \textit{multilabel classification}, which is a natural extension to single label classification.
		\begin{itemize}
			\footnotesize
			\item Input $\vx$ is an object (e.g., a picture).
			\item Output $\vy$ are multiple attributes called \textit{multilabel}
			\begin{align*}
\vy=(\underbrace{+1}_{\text{boat}},\underbrace{+1}_{\text{sea}},\underbrace{-1}_{\text{sun}},\underbrace{-1}_{\text{beach}},\underbrace{+1}_{\text{people}},\underbrace{-1}_{\text{dog}},\underbrace{-1}_{\text{cat}}).
			\end{align*}
			\item Explore a set of known object and label pairs called {training data}.
			\item Learn a \textit{mapping function} that predicts the best multilabel of a new object.
			\begin{align*}
				\vx\overset{f}{\rightarrow}\vy=(y_1,\cdots,y_k).
			\end{align*}
		\end{itemize}
		\item Multilabel classification is an active research field in machine learning.
	\end{itemize}
\end{frame}

\begin{frame}{Applications}
	\begin{itemize}
		\item Pictures can associate with multiple tags.
		\begin{tabular}{p{3cm}p{10cm}}
        \multirow{2}{*}{\includegraphics[scale = 0.13]{./figures/boatsea.png}} & \\
		& $(\underbrace{+1}_{\text{boat}},\underbrace{+1}_{\text{sea}},\underbrace{-1}_{\text{sun}},\underbrace{-1}_{\text{beach}},\underbrace{-1}_{\text{people}},\underbrace{+1}_{\text{ice}},\underbrace{+1}_{\text{land}})$\\
        \end{tabular}
		\item News articles can be assigned to multiple categories.
		\begin{tabular}{p{3cm}p{10cm}} 
        \multirow{2}{*}{\includegraphics[scale = 0.13]{./figures/titanic.jpg}} & \\
		& $(\underbrace{+1}_{\text{news}},\underbrace{+1}_{\text{economics}},\underbrace{-1}_{\text{sports}},\underbrace{-1}_{\text{politics}},\underbrace{-1}_{\text{movie}},\underbrace{-1}_{\text{science}},\underbrace{-1}_{\text{art}})$\\
        \end{tabular}
		\item Drugs can be effective for multiple symptoms.
		\begin{tabular}{p{3cm}p{10cm}} 
        \multirow{2}{*}{\includegraphics[scale = 0.3]{./figures/aspirin.jpg}} & \\
		& $(\underbrace{+1}_{\text{heart}},\underbrace{+1}_{\text{stroke}},\underbrace{+1}_{\text{blood}},\underbrace{+1}_{\text{fever}},\underbrace{-1}_{\text{digest}},\underbrace{-1}_{\text{liver}},\underbrace{+1}_{\text{swelling}})$\\
        \end{tabular}
		\item Information can spread through multiple users in social network. 
		\begin{tabular}{p{3cm}p{10cm}} 
        \multirow{2}{*}{\includegraphics[scale = 0.07]{./figures/facebookvideo.png}} & \\
		& $(\underbrace{+1}_{\text{Ted}},\underbrace{-1}_{\text{Alice}},\underbrace{+1}_{\text{David}},\underbrace{-1}_{\text{Mark}},\underbrace{+1}_{\text{Alex}},\underbrace{-1}_{\text{Zoe}},\underbrace{-1}_{\text{Frank}})$\\
        \end{tabular}
	\end{itemize}
\end{frame}


\begin{frame}{How to solve multilabel classification?}
	\begin{itemize}
		\item Reduce the multilabel classification problem as a collection of single label classification problems.
		\item Solve each individual problem independently. 
		\item Concatenate the predictions.
	\end{itemize}
	\begin{center}
		\only<1>{
		\begin{tabular}{p{1.5cm}p{0.5cm}p{3cm}} 
	    \multirow{2}{*}{\includegraphics[scale = 0.08]{./figures/facebookvideo.png}} & &\\
		& $\overset{f}{\rightarrow}$ &$(\underbrace{?}_{\text{Ted}},\underbrace{?}_{\text{Alice}},\underbrace{?}_{\text{David}},\underbrace{?}_{\text{Mark}},\underbrace{?}_{\text{Alex}},\underbrace{?}_{\text{Zoe}},\underbrace{?}_{\text{Frank}})$\\
	    \end{tabular}
		}
		\only<2>{
		\begin{tabular}{p{1.5cm}p{0.5cm}p{3cm}} 
	    \multirow{2}{*}{\includegraphics[scale = 0.08]{./figures/facebookvideo.png}} & &\\
		& $\overset{f_1}{\rightarrow}$ &$(\underbrace{+1}_{\text{Ted}},\underbrace{}_{\text{Alice}},\underbrace{}_{\text{David}},\underbrace{}_{\text{Mark}},\underbrace{}_{\text{Alex}},\underbrace{}_{\text{Zoe}},\underbrace{}_{\text{Frank}})$\\
	    \end{tabular}
		}
		\only<3>{
		\begin{tabular}{p{1.5cm}p{0.5cm}p{3cm}} 
	    \multirow{2}{*}{\includegraphics[scale = 0.08]{./figures/facebookvideo.png}} &  &\\
		& $\overset{f_2}{\rightarrow}$ &$(\underbrace{}_{\text{Ted}},\underbrace{-1}_{\text{Alice}},\underbrace{}_{\text{David}},\underbrace{}_{\text{Mark}},\underbrace{}_{\text{Alex}},\underbrace{}_{\text{Zoe}},\underbrace{}_{\text{Frank}})$\\
	    \end{tabular}
		}
		\only<4>{
		\begin{tabular}{p{1.5cm}p{0.5cm}p{3cm}} 
	    \multirow{2}{*}{\includegraphics[scale = 0.08]{./figures/facebookvideo.png}} &  &\\
		& $\overset{f_3}{\rightarrow}$ &$(\underbrace{}_{\text{Ted}},\underbrace{}_{\text{Alice}},\underbrace{+1}_{\text{David}},\underbrace{}_{\text{Mark}},\underbrace{}_{\text{Alex}},\underbrace{}_{\text{Zoe}},\underbrace{}_{\text{Frank}})$\\
	    \end{tabular}
		}
		\only<5>{
		\begin{tabular}{p{1.5cm}p{0.5cm}p{3cm}} 
	    \multirow{2}{*}{\includegraphics[scale = 0.08]{./figures/facebookvideo.png}} &  &\\
		& $\overset{f_4}{\rightarrow}$ &$(\underbrace{}_{\text{Ted}},\underbrace{}_{\text{Alice}},\underbrace{}_{\text{David}},\underbrace{-1}_{\text{Mark}},\underbrace{}_{\text{Alex}},\underbrace{}_{\text{Zoe}},\underbrace{}_{\text{Frank}})$\\
	    \end{tabular}
		}
		\only<6>{
		\begin{tabular}{p{1.5cm}p{0.5cm}p{3cm}} 
	    \multirow{2}{*}{\includegraphics[scale = 0.08]{./figures/facebookvideo.png}} &  &\\
		& $\overset{f_1,\cdots,f_7}{\rightarrow}$ &$(\underbrace{+1}_{\text{Ted}},\underbrace{-1}_{\text{Alice}},\underbrace{+1}_{\text{David}},\underbrace{-1}_{\text{Mark}},\underbrace{+1}_{\text{Alex}},\underbrace{-1}_{\text{Zoe}},\underbrace{-1}_{\text{Frank}})$\\
	    \end{tabular}
		}
	\end{center}
\end{frame}


\begin{frame}{Label correlations}
	\begin{itemize}
		\item Multiple attributes are often closely related. Similar attributes will have similar responses to an input.
		\item Social network analysis: friends have similar hobbies.
		\only<1>{
		\begin{align*}
(\underbrace{+1}_{\text{Ted}},\underbrace{-1}_{\text{Alice}},\underbrace{+1}_{\text{David}},\underbrace{-1}_{\text{Mark}},\underbrace{+1}_{\text{Alex}},\underbrace{-1}_{\text{Zoe}},\underbrace{-1}_{\text{Frank}})
		\end{align*}
		\begin{center}
			\includegraphics[scale=0.4]{./figures/facebooknetwork.pdf}
		\end{center}}
		\only<2>{
		\begin{align*}
(\underbrace{-1}_{\text{Ted}},\underbrace{+1}_{\text{Alice}},\underbrace{-1}_{\text{David}},\underbrace{+1}_{\text{Mark}},\underbrace{-1}_{\text{Alex}},\underbrace{+1}_{\text{Zoe}},\underbrace{+1}_{\text{Frank}})
		\end{align*}
		\begin{center}
			\includegraphics[scale=0.4]{./figures/facebooknetwork1.pdf}
		\end{center}}
		\item Document classification: A news about politics may be also about economics. 
		\item Label correlations can help make better predictions.
	\end{itemize}
\end{frame}


\begin{frame}{Structured output prediction}
	\begin{itemize}
		\item We want to explore the correlations of attributes to improve the performance on multilabel classification problems.
		\item In statistics, graph is a natural way to model correlations. \textit{Output graph} is defined by
		\begin{itemize}
			\footnotesize
			\item Nodes correspond to multiple attributes.
			\item Edges correspond to correlations of attributes.
		\end{itemize}
		\item \textit{Structured output prediction} method
		\begin{itemize}
			\footnotesize
			\item predicts multiple attributes of an object at the same time.
			\item explores the correlations described by an output graph.
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Contributions of this dissertation}
	\begin{itemize}
		\item The main contributions are several structured output learning algorithms that improve the performance on multilabel classification problems.
		\item In addition, it also contributes to theoretical studies on the performance of the proposed learning algorithms.
		\item For the multilabel classification problems where the output graph is given \textit{apriori}.
		\begin{itemize}
			\footnotesize
			\item Improve the performance on drug sensitivity prediction problems \citep{su10structured}.
			\item Predict reliably the spread of a content in social networks \citep{su14structured}.
		\end{itemize}
		\item For general multilabel classification problems without predefined output graph
		\begin{itemize}
			\footnotesize
			\item Several ensemble methods that combine a collection of structured output learners \citep{su11mutitask,su2013multilabelacml,su14multilabel}.
			\item A joint learning and inference framework with theoretical guarantee on the performance \citep{su14multilabelnips}.
		\end{itemize}
	\end{itemize}
\end{frame}



\begin{frame}{Future work}
	\begin{itemize}
		\item Proposed algorithms can be applied to many real world multilabel classification tasks.
		\begin{itemize}
			\footnotesize
			\item Image annotation, document classification, drug activity prediction, social network analysis.
			\item Sentiment analysis, music categorization, protein function prediction, etc.
		\end{itemize}
		\item Algorithm developments:
		\begin{itemize}
			\footnotesize
			\item Select and combine a collection of random output graphs to discover latent structure.
			\item Develop new and fast inference algorithm that allows learning on large scale datasets.
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}{Image source}
	\begin{itemize}
		\item Eniac pictures are from wikipedia.
		\item Animal pictures are from google.
		\item CAPTCHA system picture is from http://www.captcha.net.
		\item ASIRRA system picture is from http://research.microsoft.com/en-us/um/redmond/projects/asirra/.
		\item Application pictures are from google.
		\item Social network picture is from facebook.
	\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Bibliography}
%\bibliographystyle{plain}
\bibliographystyle{apalike}
 \bibliography{dissertation}
\end{frame}



\begin{frame}{}
	\begin{center}
		\large
		Thank you!
	\end{center}
\end{frame}

}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






